{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GAMMA 挑战赛任务一\n",
    "\n",
    "赛题链接\n",
    "\n",
    "    MICCAI2021 Contest - GAMMA: https://aistudio.baidu.com/aistudio/competition/detail/90\n",
    "\n",
    "比赛简介\n",
    "\n",
    "    GAMMA挑战赛是由百度在MICCAI2021研讨会OMIA8上举办的国际眼科赛事。MICCAI是由国际医学图像计算和计算机辅助干预协会举办的跨医学影像计算和计算机辅助介入两个领域的综合性学术会议，是该领域的顶级会议。OMIA是百度在MICCAI会议上组织的眼科医学影像分析研讨会，至今已举办八届。\n",
    "    \n",
    "    本次GAMMA挑战赛聚焦多模态影像中的青光眼分析，共包括三个子任务：1）青光眼分级；2）黄斑中央凹定位；3）视杯&视盘分割。\n",
    "    \n",
    "任务说明\n",
    "\n",
    "    对于GAMMA比赛任务1，目的是基于2D眼底彩照和3D OCT图像进行青光眼程度的分类。共分为3类：无青光眼、早期青光眼、中期及晚期青光眼。\n",
    "\n",
    "数据集说明\n",
    "\n",
    "    使用的数据集为GAMMA比赛释放的多模态眼底图像。\n",
    "    \n",
    "方案介绍\n",
    "\n",
    "    本项目在基线的基础上，使用了Resnet152，经过多次训练得到了8.95的成绩。这一成绩的偶然性较高，在当前模型下可能难以获得更好的成绩了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 测试记录\n",
    "\n",
    "| index | 版本 | score | Kappa | 备注 |\n",
    "| -------- | -------- | -------- | -------- | -------- |\n",
    "| 0     | 版本0     | 6.05162\t|0.60516     | 官方基线，保存为best_model_0.7458|\n",
    "|1     | 版本1     | 7.6173\t|0.76173     | 全部Resnet使用152，保存为best_model_0.9123|\n",
    "|2     | 版本1     | 6.84392\t|0.68439     | 接续1进行测试，保存为best_model_0.8276|\n",
    "|3     | 版本1     |8.09102\t|0.8091     | 接续1进行测试，保存为best_model_0.8157|\n",
    "|4     | 版本1     |7.97508\t|0.79751     | 接续3进行测试，也许应该重新划分数据集|\n",
    "|5     | 版本1     |8.18841\t|0.81884     | 接续3进行测试，保存为best_model_0.9231|\n",
    "|6     | 版本2     |8.52667\t|0.85267\t     | 接续5进行测试，保存为best_model_8.52667|\n",
    "|7     | 版本2     |8.95949\t|0.89595\t     | 接续6进行测试，保存为best_model_8.95|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- 解压数据包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! wget https://dataset-bj.cdn.bcebos.com/%E5%8C%BB%E7%96%97%E6%AF%94%E8%B5%9B/task1_gamma_grading.tar.gz.00\r\n",
    "! wget https://dataset-bj.cdn.bcebos.com/%E5%8C%BB%E7%96%97%E6%AF%94%E8%B5%9B/task1_gamma_grading.tar.gz.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! cat task1_gamma_grading.tar.gz* | tar -xzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.vision.models import resnet34\n",
    "import paddle.vision.models\n",
    "\n",
    "import transforms as trans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchsize = 16 # 批大小,\n",
    "oct_img_size = [512, 512]\n",
    "image_size = 256\n",
    "iters = 1000 # 迭代次数\n",
    "val_ratio = 0.2 # 训练/验证数据划分比例，80 / 20\n",
    "trainset_root = \"Glaucoma_grading/training/multi-modality_images\"\n",
    "testset_root = \"Glaucoma_grading/testing/multi-modality_images\"\n",
    "num_workers = 4\n",
    "init_lr = 1e-4\n",
    "optimizer_type = \"adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练 / 验证数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nums: 100, train: 80, val: 20\n"
     ]
    }
   ],
   "source": [
    "filelists = os.listdir(trainset_root)\n",
    "# train_filelists, val_filelists = train_test_split(filelists, test_size=val_ratio, random_state=42)\n",
    "train_filelists, val_filelists = train_test_split(filelists, test_size=val_ratio)\n",
    "print(\"Total Nums: {}, train: {}, val: {}\".format(len(filelists), len(train_filelists), len(val_filelists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- 根据“患者id”加载oct图像和眼底图像\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GAMMA_sub1_dataset(paddle.io.Dataset):\n",
    "    \"\"\"\n",
    "    getitem() output:\n",
    "    \n",
    "    \tfundus_img: RGB uint8 image with shape (3, image_size, image_size)\n",
    "        \n",
    "        oct_img:    Uint8 image with shape (256, oct_img_size[0], oct_img_size[1])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 img_transforms,\n",
    "                 oct_transforms,\n",
    "                 dataset_root,\n",
    "                 label_file='',\n",
    "                 filelists=None,\n",
    "                 num_classes=3,\n",
    "                 mode='train'):\n",
    "\n",
    "        self.dataset_root = dataset_root\n",
    "        self.img_transforms = img_transforms\n",
    "        self.oct_transforms = oct_transforms\n",
    "        self.mode = mode.lower()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            label = {row['data']: row[1:].values \n",
    "                        for _, row in pd.read_excel(label_file).iterrows()}\n",
    "\n",
    "            self.file_list = [[f, label[int(f)]] for f in os.listdir(dataset_root)]\n",
    "        elif self.mode == \"test\":\n",
    "            self.file_list = [[f, None] for f in os.listdir(dataset_root)]\n",
    "        \n",
    "        if filelists is not None:\n",
    "            self.file_list = [item for item in self.file_list if item[0] in filelists]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_index, label = self.file_list[idx]\n",
    "\n",
    "        fundus_img_path = os.path.join(self.dataset_root, real_index, real_index + \".jpg\")\n",
    "        oct_series_list = sorted(os.listdir(os.path.join(self.dataset_root, real_index, real_index)), \n",
    "                                    key=lambda x: int(x.strip(\"_\")[0]))\n",
    "\n",
    "        fundus_img = cv2.imread(fundus_img_path)[:, :, ::-1] # BGR -> RGB\n",
    "        oct_series_0 = cv2.imread(os.path.join(self.dataset_root, real_index, real_index, oct_series_list[0]), \n",
    "                                    cv2.IMREAD_GRAYSCALE)\n",
    "        oct_img = np.zeros((len(oct_series_list), oct_series_0.shape[0], oct_series_0.shape[1], 1), dtype=\"uint8\")\n",
    "\n",
    "        for k, p in enumerate(oct_series_list):\n",
    "            oct_img[k] = cv2.imread(\n",
    "                os.path.join(self.dataset_root, real_index, real_index, p), cv2.IMREAD_GRAYSCALE)[..., np.newaxis]\n",
    "\n",
    "        if self.img_transforms is not None:\n",
    "            fundus_img = self.img_transforms(fundus_img)\n",
    "        if self.oct_transforms is not None:\n",
    "            oct_img = self.oct_transforms(oct_img)\n",
    " \n",
    "        # normlize on GPU to save CPU Memory and IO consuming.\n",
    "        # fundus_img = (fundus_img / 255.).astype(\"float32\")\n",
    "        # oct_img = (oct_img / 255.).astype(\"float32\")\n",
    "\n",
    "        fundus_img = fundus_img.transpose(2, 0, 1) # H, W, C -> C, H, W\n",
    "        oct_img = oct_img.squeeze(-1) # D, H, W, 1 -> D, H, W\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return fundus_img, oct_img, real_index\n",
    "        if self.mode == \"train\":\n",
    "            label = label.argmax()\n",
    "            return fundus_img, oct_img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_train_transforms = trans.Compose([\n",
    "    trans.RandomResizedCrop(\n",
    "        # image_size, scale=(0.90, 1.1), ratio=(0.90, 1.1)),\n",
    "        image_size, scale=(0.70, 1.3), ratio=(0.70, 1.3)),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(60)\n",
    "])\n",
    "\n",
    "oct_train_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(60)\n",
    "])\n",
    "\n",
    "img_val_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size))\n",
    "])\n",
    "\n",
    "oct_val_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(nn.Layer):\n",
    "    \"\"\"\n",
    "    simply create a 2-branch network, and concat global pooled feature vector.\n",
    "    each branch = single resnet34\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fundus_branch = paddle.vision.models.resnet152(pretrained=True, num_classes=0) # 移除最后一层全连接层\n",
    "        self.oct_branch = paddle.vision.models.resnet152(pretrained=True, num_classes=0) # 移除最后一层全连接层\n",
    "        self.decision_branch = nn.Linear(2048 * 1 * 2, 3) \n",
    "        \n",
    "        # 在oct_branch更改第一个卷积层通道数\n",
    "        self.oct_branch.conv1 = nn.Conv2D(256, 64,\n",
    "                                        kernel_size=7,\n",
    "                                        stride=2,\n",
    "                                        padding=3,\n",
    "                                        bias_attr=False)\n",
    "\n",
    "    def forward(self, fundus_img, oct_img):\n",
    "        b1 = self.fundus_branch(fundus_img)\n",
    "        b2 = self.oct_branch(oct_img)\n",
    "        b1 = paddle.flatten(b1, 1)\n",
    "        b2 = paddle.flatten(b2, 1)\n",
    "        logit = self.decision_branch(paddle.concat([b1, b2], 1))\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 功能函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, iters, train_dataloader, val_dataloader, optimizer, criterion, log_interval, eval_interval):\n",
    "    iter = 0\n",
    "    model.train()\n",
    "    avg_loss_list = []\n",
    "    avg_kappa_list = []\n",
    "    best_kappa = 0.\n",
    "    while iter < iters:\n",
    "        for data in train_dataloader:\n",
    "            iter += 1\n",
    "            if iter > iters:\n",
    "                break\n",
    "            fundus_imgs = (data[0] / 255.).astype(\"float32\")\n",
    "            oct_imgs = (data[1] / 255.).astype(\"float32\")\n",
    "            labels = data[2].astype('int64')\n",
    "\n",
    "            logits = model(fundus_imgs, oct_imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "            # acc = paddle.metric.accuracy(input=logits, label=labels.reshape((-1, 1)), k=1)\n",
    "            for p, l in zip(logits.numpy().argmax(1), labels.numpy()):\n",
    "                avg_kappa_list.append([p, l])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.clear_gradients()\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "\n",
    "            if iter % log_interval == 0:\n",
    "                avg_loss = np.array(avg_loss_list).mean()\n",
    "                avg_kappa_list = np.array(avg_kappa_list)\n",
    "                avg_kappa = cohen_kappa_score(avg_kappa_list[:, 0], avg_kappa_list[:, 1], weights='quadratic')\n",
    "                avg_loss_list = []\n",
    "                avg_kappa_list = []\n",
    "                print(\"[TRAIN] iter={}/{} avg_loss={:.4f} avg_kappa={:.4f}\".format(iter, iters, avg_loss, avg_kappa))\n",
    "\n",
    "            if iter % eval_interval == 0:\n",
    "                avg_loss, avg_kappa = val(model, val_dataloader, criterion)\n",
    "                print(\"[EVAL] iter={}/{} avg_loss={:.4f} kappa={:.4f}\".format(iter, iters, avg_loss, avg_kappa))\n",
    "                # if avg_kappa >= best_kappa:\n",
    "                if 1:\n",
    "                    best_kappa = avg_kappa\n",
    "                    paddle.save(model.state_dict(),\n",
    "                            os.path.join(\"{}_best_model_{:.4f}\".format(iter,best_kappa), 'model.pdparams'))\n",
    "                model.train()\n",
    "\n",
    "def val(model, val_dataloader, criterion):\n",
    "    model.eval()\n",
    "    avg_loss_list = []\n",
    "    cache = []\n",
    "    with paddle.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            fundus_imgs = (data[0] / 255.).astype(\"float32\")\n",
    "            oct_imgs = (data[1] / 255.).astype(\"float32\")\n",
    "            labels = data[2].astype('int64')\n",
    "            \n",
    "            logits = model(fundus_imgs, oct_imgs)\n",
    "            for p, l in zip(logits.numpy().argmax(1), labels.numpy()):\n",
    "                cache.append([p, l])\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            # acc = paddle.metric.accuracy(input=logits, label=labels.reshape((-1, 1)), k=1)\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "    cache = np.array(cache)\n",
    "    kappa = cohen_kappa_score(cache[:, 0], cache[:, 1], weights='quadratic')\n",
    "    avg_loss = np.array(avg_loss_list).mean()\n",
    "\n",
    "    return avg_loss, kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_train_transforms = trans.Compose([\n",
    "    trans.RandomResizedCrop(\n",
    "        image_size, scale=(0.90, 1.1), ratio=(0.90, 1.1)),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(30)\n",
    "])\n",
    "\n",
    "oct_train_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "img_val_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size))\n",
    "])\n",
    "\n",
    "oct_val_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size)\n",
    "])\n",
    "\n",
    "train_dataset = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                        img_transforms=img_train_transforms,\n",
    "                        oct_transforms=oct_train_transforms,\n",
    "                        filelists=train_filelists,\n",
    "                        label_file='Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx')\n",
    "\n",
    "val_dataset = GAMMA_sub1_dataset(dataset_root=trainset_root, \n",
    "                        img_transforms=img_val_transforms,\n",
    "                        oct_transforms=oct_val_transforms,\n",
    "                        filelists=val_filelists,\n",
    "                        label_file='Glaucoma_grading/training/glaucoma_grading_training_GT.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(train_dataset, batch_size=batchsize, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "val_loader = paddle.io.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(val_dataset, batch_size=batchsize, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "if optimizer_type == \"adam\":\n",
    "    optimizer = paddle.optimizer.Adam(init_lr, parameters=model.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 接续上次的运行结果\r\n",
    "best_model_path = \"./best_model_8.95/model.pdparams\"\r\n",
    "para_state_dict = paddle.load(best_model_path)\r\n",
    "model.set_state_dict(para_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train(model, iters, train_loader, val_loader, optimizer, criterion, log_interval=10, eval_interval=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 预测阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "100 8.89641\n",
    "200 7.8391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 17:53:38,331 - INFO - unique_endpoints {''}\n",
      "2021-11-13 17:53:38,332 - INFO - File /home/aistudio/.cache/paddle/hapi/weights/resnet152.pdparams md5 checking...\n",
      "2021-11-13 17:53:39,126 - INFO - Found /home/aistudio/.cache/paddle/hapi/weights/resnet152.pdparams\n",
      "2021-11-13 17:53:41,081 - INFO - unique_endpoints {''}\n",
      "2021-11-13 17:53:41,082 - INFO - File /home/aistudio/.cache/paddle/hapi/weights/resnet152.pdparams md5 checking...\n",
      "2021-11-13 17:53:41,877 - INFO - Found /home/aistudio/.cache/paddle/hapi/weights/resnet152.pdparams\n"
     ]
    }
   ],
   "source": [
    "best_model_path = \"./200_best_model_1.0000/model.pdparams\"\n",
    "model = Model()\n",
    "para_state_dict = paddle.load(best_model_path)\n",
    "model.set_state_dict(para_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_test_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size))\n",
    "])\n",
    "\n",
    "oct_test_transforms = trans.Compose([\n",
    "    trans.CenterCrop([256] + oct_img_size)\n",
    "])\n",
    "\n",
    "test_dataset = GAMMA_sub1_dataset(dataset_root=testset_root, \n",
    "                        img_transforms=img_test_transforms,\n",
    "                        oct_transforms=oct_test_transforms,\n",
    "                        mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0142/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0176/100"
     ]
    }
   ],
   "source": [
    "cache = []\n",
    "for fundus_img, oct_img, idx in test_dataset:\n",
    "    print('\\r'+str(idx)+'/100',end='')\n",
    "    fundus_img = fundus_img[np.newaxis, ...]\n",
    "    oct_img = oct_img[np.newaxis, ...]\n",
    "\n",
    "    fundus_img = paddle.to_tensor((fundus_img / 255.).astype(\"float32\"))\n",
    "    oct_img = paddle.to_tensor((oct_img / 255.).astype(\"float32\"))\n",
    "\n",
    "    logits = model(fundus_img, oct_img)\n",
    "    cache.append([idx, logits.numpy().argmax(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_result = pd.DataFrame(cache, columns=['data', 'dense_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_result['non'] = submission_result['dense_pred'].apply(lambda x: int(x[0] == 0))\n",
    "submission_result['early'] = submission_result['dense_pred'].apply(lambda x: int(x[0] == 1))\n",
    "submission_result['mid_advanced'] = submission_result['dense_pred'].apply(lambda x: int(x[0] == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_result[['data', 'non', 'early', 'mid_advanced']].to_csv(\"./submission_sub1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\n",
    "\n",
    "- 比赛基线的双分支网络还是靠谱的，直接套用可以获得较高的得分。\n",
    "   \n",
    "- 在目前的网络结构下，我很难看到更好的结果了，可以考虑对网络结构进行变迁从而获得更好的结果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
